(window["webpackJsonp"] = window["webpackJsonp"] || []).push([["modules/vendor.scheduler"],{

/***/ "./node_modules/scheduler/cjs/scheduler-tracing.development.js":
/*!*********************************************************************!*\
  !*** ./node_modules/scheduler/cjs/scheduler-tracing.development.js ***!
  \*********************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/** @license React v0.17.0\n * scheduler-tracing.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\n\n\nif (true) {\n  (function() {\n'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\n// Helps identify side effects in begin-phase lifecycle hooks and setState reducers:\n\n // In some cases, StrictMode should also double-render lifecycles.\n// This can be confusing for tests though,\n// And it can be bad for performance in production.\n// This feature flag can be used to control the behavior:\n\n // To preserve the \"Pause on caught exceptions\" behavior of the debugger, we\n// replay the begin phase of a failed component inside invokeGuardedCallback.\n\n // Warn about deprecated, async-unsafe lifecycles; relates to RFC #6:\n\n // Gather advanced timing metrics for Profiler subtrees.\n\n // Trace which interactions trigger each commit.\n\nvar enableSchedulerTracing = true; // SSR experiments\n\n\n // Only used in www builds.\n\n // Only used in www builds.\n\n // Disable javascript: URL strings in href for XSS protection.\n\n // React Fire: prevent the value and checked attributes from syncing\n// with their related DOM properties\n\n // These APIs will no longer be \"unstable\" in the upcoming 16.7 release,\n// Control this behavior with a flag to support 16.6 minor releases in the meanwhile.\n\n\n // Experimental React Flare event system and event components support.\n\n // Experimental Host Component support.\n\n // Experimental Scope support.\n\n // New API for JSX transforms to target - https://github.com/reactjs/rfcs/pull/107\n\n // We will enforce mocking scheduler with scheduler/unstable_mock at some point. (v17?)\n// Till then, we warn about the missing mock, but still fallback to a sync mode compatible version\n\n // For tests, we flush suspense fallbacks in an act scope;\n// *except* in some of our own tests, where we test incremental loading states.\n\n // Add a callback property to suspense to notify which promises are currently\n// in the update queue. This allows reporting and tracing of what is causing\n// the user to see a loading state.\n// Also allows hydration callbacks to fire when a dehydrated boundary gets\n// hydrated or deleted.\n\n // Part of the simplification of React.createElement so we can eventually move\n// from React.createElement to React.jsx\n// https://github.com/reactjs/rfcs/blob/createlement-rfc/text/0000-create-element-changes.md\n\nvar DEFAULT_THREAD_ID = 0; // Counters used to generate unique IDs.\n\nvar interactionIDCounter = 0;\nvar threadIDCounter = 0; // Set of currently traced interactions.\n// Interactions \"stack\"–\n// Meaning that newly traced interactions are appended to the previously active set.\n// When an interaction goes out of scope, the previous set (if any) is restored.\n\nexports.__interactionsRef = null; // Listener(s) to notify when interactions begin and end.\n\nexports.__subscriberRef = null;\n\nif (enableSchedulerTracing) {\n  exports.__interactionsRef = {\n    current: new Set()\n  };\n  exports.__subscriberRef = {\n    current: null\n  };\n}\n\nfunction unstable_clear(callback) {\n  if (!enableSchedulerTracing) {\n    return callback();\n  }\n\n  var prevInteractions = exports.__interactionsRef.current;\n  exports.__interactionsRef.current = new Set();\n\n  try {\n    return callback();\n  } finally {\n    exports.__interactionsRef.current = prevInteractions;\n  }\n}\nfunction unstable_getCurrent() {\n  if (!enableSchedulerTracing) {\n    return null;\n  } else {\n    return exports.__interactionsRef.current;\n  }\n}\nfunction unstable_getThreadID() {\n  return ++threadIDCounter;\n}\nfunction unstable_trace(name, timestamp, callback) {\n  var threadID = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : DEFAULT_THREAD_ID;\n\n  if (!enableSchedulerTracing) {\n    return callback();\n  }\n\n  var interaction = {\n    __count: 1,\n    id: interactionIDCounter++,\n    name: name,\n    timestamp: timestamp\n  };\n  var prevInteractions = exports.__interactionsRef.current; // Traced interactions should stack/accumulate.\n  // To do that, clone the current interactions.\n  // The previous set will be restored upon completion.\n\n  var interactions = new Set(prevInteractions);\n  interactions.add(interaction);\n  exports.__interactionsRef.current = interactions;\n  var subscriber = exports.__subscriberRef.current;\n  var returnValue;\n\n  try {\n    if (subscriber !== null) {\n      subscriber.onInteractionTraced(interaction);\n    }\n  } finally {\n    try {\n      if (subscriber !== null) {\n        subscriber.onWorkStarted(interactions, threadID);\n      }\n    } finally {\n      try {\n        returnValue = callback();\n      } finally {\n        exports.__interactionsRef.current = prevInteractions;\n\n        try {\n          if (subscriber !== null) {\n            subscriber.onWorkStopped(interactions, threadID);\n          }\n        } finally {\n          interaction.__count--; // If no async work was scheduled for this interaction,\n          // Notify subscribers that it's completed.\n\n          if (subscriber !== null && interaction.__count === 0) {\n            subscriber.onInteractionScheduledWorkCompleted(interaction);\n          }\n        }\n      }\n    }\n  }\n\n  return returnValue;\n}\nfunction unstable_wrap(callback) {\n  var threadID = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : DEFAULT_THREAD_ID;\n\n  if (!enableSchedulerTracing) {\n    return callback;\n  }\n\n  var wrappedInteractions = exports.__interactionsRef.current;\n  var subscriber = exports.__subscriberRef.current;\n\n  if (subscriber !== null) {\n    subscriber.onWorkScheduled(wrappedInteractions, threadID);\n  } // Update the pending async work count for the current interactions.\n  // Update after calling subscribers in case of error.\n\n\n  wrappedInteractions.forEach(function (interaction) {\n    interaction.__count++;\n  });\n  var hasRun = false;\n\n  function wrapped() {\n    var prevInteractions = exports.__interactionsRef.current;\n    exports.__interactionsRef.current = wrappedInteractions;\n    subscriber = exports.__subscriberRef.current;\n\n    try {\n      var returnValue;\n\n      try {\n        if (subscriber !== null) {\n          subscriber.onWorkStarted(wrappedInteractions, threadID);\n        }\n      } finally {\n        try {\n          returnValue = callback.apply(undefined, arguments);\n        } finally {\n          exports.__interactionsRef.current = prevInteractions;\n\n          if (subscriber !== null) {\n            subscriber.onWorkStopped(wrappedInteractions, threadID);\n          }\n        }\n      }\n\n      return returnValue;\n    } finally {\n      if (!hasRun) {\n        // We only expect a wrapped function to be executed once,\n        // But in the event that it's executed more than once–\n        // Only decrement the outstanding interaction counts once.\n        hasRun = true; // Update pending async counts for all wrapped interactions.\n        // If this was the last scheduled async work for any of them,\n        // Mark them as completed.\n\n        wrappedInteractions.forEach(function (interaction) {\n          interaction.__count--;\n\n          if (subscriber !== null && interaction.__count === 0) {\n            subscriber.onInteractionScheduledWorkCompleted(interaction);\n          }\n        });\n      }\n    }\n  }\n\n  wrapped.cancel = function cancel() {\n    subscriber = exports.__subscriberRef.current;\n\n    try {\n      if (subscriber !== null) {\n        subscriber.onWorkCanceled(wrappedInteractions, threadID);\n      }\n    } finally {\n      // Update pending async counts for all wrapped interactions.\n      // If this was the last scheduled async work for any of them,\n      // Mark them as completed.\n      wrappedInteractions.forEach(function (interaction) {\n        interaction.__count--;\n\n        if (subscriber && interaction.__count === 0) {\n          subscriber.onInteractionScheduledWorkCompleted(interaction);\n        }\n      });\n    }\n  };\n\n  return wrapped;\n}\n\nvar subscribers = null;\n\nif (enableSchedulerTracing) {\n  subscribers = new Set();\n}\n\nfunction unstable_subscribe(subscriber) {\n  if (enableSchedulerTracing) {\n    subscribers.add(subscriber);\n\n    if (subscribers.size === 1) {\n      exports.__subscriberRef.current = {\n        onInteractionScheduledWorkCompleted: onInteractionScheduledWorkCompleted,\n        onInteractionTraced: onInteractionTraced,\n        onWorkCanceled: onWorkCanceled,\n        onWorkScheduled: onWorkScheduled,\n        onWorkStarted: onWorkStarted,\n        onWorkStopped: onWorkStopped\n      };\n    }\n  }\n}\nfunction unstable_unsubscribe(subscriber) {\n  if (enableSchedulerTracing) {\n    subscribers.delete(subscriber);\n\n    if (subscribers.size === 0) {\n      exports.__subscriberRef.current = null;\n    }\n  }\n}\n\nfunction onInteractionTraced(interaction) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onInteractionTraced(interaction);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onInteractionScheduledWorkCompleted(interaction) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onInteractionScheduledWorkCompleted(interaction);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkScheduled(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkScheduled(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkStarted(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkStarted(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkStopped(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkStopped(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nfunction onWorkCanceled(interactions, threadID) {\n  var didCatchError = false;\n  var caughtError = null;\n  subscribers.forEach(function (subscriber) {\n    try {\n      subscriber.onWorkCanceled(interactions, threadID);\n    } catch (error) {\n      if (!didCatchError) {\n        didCatchError = true;\n        caughtError = error;\n      }\n    }\n  });\n\n  if (didCatchError) {\n    throw caughtError;\n  }\n}\n\nexports.unstable_clear = unstable_clear;\nexports.unstable_getCurrent = unstable_getCurrent;\nexports.unstable_getThreadID = unstable_getThreadID;\nexports.unstable_trace = unstable_trace;\nexports.unstable_wrap = unstable_wrap;\nexports.unstable_subscribe = unstable_subscribe;\nexports.unstable_unsubscribe = unstable_unsubscribe;\n  })();\n}\n\n\n//# sourceURL=webpack:///./node_modules/scheduler/cjs/scheduler-tracing.development.js?");

/***/ }),

/***/ "./node_modules/scheduler/cjs/scheduler.development.js":
/*!*************************************************************!*\
  !*** ./node_modules/scheduler/cjs/scheduler.development.js ***!
  \*************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("/** @license React v0.17.0\n * scheduler.development.js\n *\n * Copyright (c) Facebook, Inc. and its affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n */\n\n\n\n\n\nif (true) {\n  (function() {\n'use strict';\n\nObject.defineProperty(exports, '__esModule', { value: true });\n\nvar enableSchedulerDebugging = false;\nvar enableIsInputPending = false;\nvar enableMessageLoopImplementation = true;\nvar enableProfiling = true;\n\n// works by scheduling a requestAnimationFrame, storing the time for the start\n// of the frame, then scheduling a postMessage which gets scheduled after paint.\n// Within the postMessage handler do as much work as possible until time + frame\n// rate. By separating the idle call into a separate event tick we ensure that\n// layout, paint and other browser work is counted against the available time.\n// The frame rate is dynamically adjusted.\n\nvar requestHostCallback;\n\nvar requestHostTimeout;\nvar cancelHostTimeout;\nvar shouldYieldToHost;\nvar requestPaint;\n\n\n\nif ( // If Scheduler runs in a non-DOM environment, it falls back to a naive\n// implementation using setTimeout.\ntypeof window === 'undefined' || // Check if MessageChannel is supported, too.\ntypeof MessageChannel !== 'function') {\n  // If this accidentally gets imported in a non-browser environment, e.g. JavaScriptCore,\n  // fallback to a naive implementation.\n  var _callback = null;\n  var _timeoutID = null;\n\n  var _flushCallback = function () {\n    if (_callback !== null) {\n      try {\n        var currentTime = exports.unstable_now();\n        var hasRemainingTime = true;\n\n        _callback(hasRemainingTime, currentTime);\n\n        _callback = null;\n      } catch (e) {\n        setTimeout(_flushCallback, 0);\n        throw e;\n      }\n    }\n  };\n\n  var initialTime = Date.now();\n\n  exports.unstable_now = function () {\n    return Date.now() - initialTime;\n  };\n\n  requestHostCallback = function (cb) {\n    if (_callback !== null) {\n      // Protect against re-entrancy.\n      setTimeout(requestHostCallback, 0, cb);\n    } else {\n      _callback = cb;\n      setTimeout(_flushCallback, 0);\n    }\n  };\n\n  requestHostTimeout = function (cb, ms) {\n    _timeoutID = setTimeout(cb, ms);\n  };\n\n  cancelHostTimeout = function () {\n    clearTimeout(_timeoutID);\n  };\n\n  shouldYieldToHost = function () {\n    return false;\n  };\n\n  requestPaint = exports.unstable_forceFrameRate = function () {};\n} else {\n  // Capture local references to native APIs, in case a polyfill overrides them.\n  var performance = window.performance;\n  var _Date = window.Date;\n  var _setTimeout = window.setTimeout;\n  var _clearTimeout = window.clearTimeout;\n  var requestAnimationFrame = window.requestAnimationFrame;\n  var cancelAnimationFrame = window.cancelAnimationFrame;\n\n  if (typeof console !== 'undefined') {\n    // TODO: Remove fb.me link\n    if (typeof requestAnimationFrame !== 'function') {\n      console.error(\"This browser doesn't support requestAnimationFrame. \" + 'Make sure that you load a ' + 'polyfill in older browsers. https://fb.me/react-polyfills');\n    }\n\n    if (typeof cancelAnimationFrame !== 'function') {\n      console.error(\"This browser doesn't support cancelAnimationFrame. \" + 'Make sure that you load a ' + 'polyfill in older browsers. https://fb.me/react-polyfills');\n    }\n  }\n\n  if (typeof performance === 'object' && typeof performance.now === 'function') {\n    exports.unstable_now = function () {\n      return performance.now();\n    };\n  } else {\n    var _initialTime = _Date.now();\n\n    exports.unstable_now = function () {\n      return _Date.now() - _initialTime;\n    };\n  }\n\n  var isRAFLoopRunning = false;\n  var isMessageLoopRunning = false;\n  var scheduledHostCallback = null;\n  var rAFTimeoutID = -1;\n  var taskTimeoutID = -1;\n  var frameLength = enableMessageLoopImplementation ? // We won't attempt to align with the vsync. Instead we'll yield multiple\n  // times per frame, often enough to keep it responsive even at really\n  // high frame rates > 120.\n  5 : // Use a heuristic to measure the frame rate and yield at the end of the\n  // frame. We start out assuming that we run at 30fps but then the\n  // heuristic tracking will adjust this value to a faster fps if we get\n  // more frequent animation frames.\n  33.33;\n  var prevRAFTime = -1;\n  var prevRAFInterval = -1;\n  var frameDeadline = 0;\n  var fpsLocked = false; // TODO: Make this configurable\n  // TODO: Adjust this based on priority?\n\n  var maxFrameLength = 300;\n  var needsPaint = false;\n\n  if (enableIsInputPending && navigator !== undefined && navigator.scheduling !== undefined && navigator.scheduling.isInputPending !== undefined) {\n    var scheduling = navigator.scheduling;\n\n    shouldYieldToHost = function () {\n      var currentTime = exports.unstable_now();\n\n      if (currentTime >= frameDeadline) {\n        // There's no time left in the frame. We may want to yield control of\n        // the main thread, so the browser can perform high priority tasks. The\n        // main ones are painting and user input. If there's a pending paint or\n        // a pending input, then we should yield. But if there's neither, then\n        // we can yield less often while remaining responsive. We'll eventually\n        // yield regardless, since there could be a pending paint that wasn't\n        // accompanied by a call to `requestPaint`, or other main thread tasks\n        // like network events.\n        if (needsPaint || scheduling.isInputPending()) {\n          // There is either a pending paint or a pending input.\n          return true;\n        } // There's no pending input. Only yield if we've reached the max\n        // frame length.\n\n\n        return currentTime >= frameDeadline + maxFrameLength;\n      } else {\n        // There's still time left in the frame.\n        return false;\n      }\n    };\n\n    requestPaint = function () {\n      needsPaint = true;\n    };\n  } else {\n    // `isInputPending` is not available. Since we have no way of knowing if\n    // there's pending input, always yield at the end of the frame.\n    shouldYieldToHost = function () {\n      return exports.unstable_now() >= frameDeadline;\n    }; // Since we yield every frame regardless, `requestPaint` has no effect.\n\n\n    requestPaint = function () {};\n  }\n\n  exports.unstable_forceFrameRate = function (fps) {\n    if (fps < 0 || fps > 125) {\n      console.error('forceFrameRate takes a positive int between 0 and 125, ' + 'forcing framerates higher than 125 fps is not unsupported');\n      return;\n    }\n\n    if (fps > 0) {\n      frameLength = Math.floor(1000 / fps);\n      fpsLocked = true;\n    } else {\n      // reset the framerate\n      frameLength = 33.33;\n      fpsLocked = false;\n    }\n  };\n\n  var performWorkUntilDeadline = function () {\n    if (enableMessageLoopImplementation) {\n      if (scheduledHostCallback !== null) {\n        var currentTime = exports.unstable_now(); // Yield after `frameLength` ms, regardless of where we are in the vsync\n        // cycle. This means there's always time remaining at the beginning of\n        // the message event.\n\n        frameDeadline = currentTime + frameLength;\n        var hasTimeRemaining = true;\n\n        try {\n          var hasMoreWork = scheduledHostCallback(hasTimeRemaining, currentTime);\n\n          if (!hasMoreWork) {\n            isMessageLoopRunning = false;\n            scheduledHostCallback = null;\n          } else {\n            // If there's more work, schedule the next message event at the end\n            // of the preceding one.\n            port.postMessage(null);\n          }\n        } catch (error) {\n          // If a scheduler task throws, exit the current browser task so the\n          // error can be observed.\n          port.postMessage(null);\n          throw error;\n        }\n      } else {\n        isMessageLoopRunning = false;\n      } // Yielding to the browser will give it a chance to paint, so we can\n      // reset this.\n\n\n      needsPaint = false;\n    } else {\n      if (scheduledHostCallback !== null) {\n        var _currentTime = exports.unstable_now();\n\n        var _hasTimeRemaining = frameDeadline - _currentTime > 0;\n\n        try {\n          var _hasMoreWork = scheduledHostCallback(_hasTimeRemaining, _currentTime);\n\n          if (!_hasMoreWork) {\n            scheduledHostCallback = null;\n          }\n        } catch (error) {\n          // If a scheduler task throws, exit the current browser task so the\n          // error can be observed, and post a new task as soon as possible\n          // so we can continue where we left off.\n          port.postMessage(null);\n          throw error;\n        }\n      } // Yielding to the browser will give it a chance to paint, so we can\n      // reset this.\n\n\n      needsPaint = false;\n    }\n  };\n\n  var channel = new MessageChannel();\n  var port = channel.port2;\n  channel.port1.onmessage = performWorkUntilDeadline;\n\n  var onAnimationFrame = function (rAFTime) {\n    if (scheduledHostCallback === null) {\n      // No scheduled work. Exit.\n      prevRAFTime = -1;\n      prevRAFInterval = -1;\n      isRAFLoopRunning = false;\n      return;\n    } // Eagerly schedule the next animation callback at the beginning of the\n    // frame. If the scheduler queue is not empty at the end of the frame, it\n    // will continue flushing inside that callback. If the queue *is* empty,\n    // then it will exit immediately. Posting the callback at the start of the\n    // frame ensures it's fired within the earliest possible frame. If we\n    // waited until the end of the frame to post the callback, we risk the\n    // browser skipping a frame and not firing the callback until the frame\n    // after that.\n\n\n    isRAFLoopRunning = true;\n    requestAnimationFrame(function (nextRAFTime) {\n      _clearTimeout(rAFTimeoutID);\n\n      onAnimationFrame(nextRAFTime);\n    }); // requestAnimationFrame is throttled when the tab is backgrounded. We\n    // don't want to stop working entirely. So we'll fallback to a timeout loop.\n    // TODO: Need a better heuristic for backgrounded work.\n\n    var onTimeout = function () {\n      frameDeadline = exports.unstable_now() + frameLength / 2;\n      performWorkUntilDeadline();\n      rAFTimeoutID = _setTimeout(onTimeout, frameLength * 3);\n    };\n\n    rAFTimeoutID = _setTimeout(onTimeout, frameLength * 3);\n\n    if (prevRAFTime !== -1 && // Make sure this rAF time is different from the previous one. This check\n    // could fail if two rAFs fire in the same frame.\n    rAFTime - prevRAFTime > 0.1) {\n      var rAFInterval = rAFTime - prevRAFTime;\n\n      if (!fpsLocked && prevRAFInterval !== -1) {\n        // We've observed two consecutive frame intervals. We'll use this to\n        // dynamically adjust the frame rate.\n        //\n        // If one frame goes long, then the next one can be short to catch up.\n        // If two frames are short in a row, then that's an indication that we\n        // actually have a higher frame rate than what we're currently\n        // optimizing. For example, if we're running on 120hz display or 90hz VR\n        // display. Take the max of the two in case one of them was an anomaly\n        // due to missed frame deadlines.\n        if (rAFInterval < frameLength && prevRAFInterval < frameLength) {\n          frameLength = rAFInterval < prevRAFInterval ? prevRAFInterval : rAFInterval;\n\n          if (frameLength < 8.33) {\n            // Defensive coding. We don't support higher frame rates than 120hz.\n            // If the calculated frame length gets lower than 8, it is probably\n            // a bug.\n            frameLength = 8.33;\n          }\n        }\n      }\n\n      prevRAFInterval = rAFInterval;\n    }\n\n    prevRAFTime = rAFTime;\n    frameDeadline = rAFTime + frameLength; // We use the postMessage trick to defer idle work until after the repaint.\n\n    port.postMessage(null);\n  };\n\n  requestHostCallback = function (callback) {\n    scheduledHostCallback = callback;\n\n    if (enableMessageLoopImplementation) {\n      if (!isMessageLoopRunning) {\n        isMessageLoopRunning = true;\n        port.postMessage(null);\n      }\n    } else {\n      if (!isRAFLoopRunning) {\n        // Start a rAF loop.\n        isRAFLoopRunning = true;\n        requestAnimationFrame(function (rAFTime) {\n          onAnimationFrame(rAFTime);\n        });\n      }\n    }\n  };\n\n  requestHostTimeout = function (callback, ms) {\n    taskTimeoutID = _setTimeout(function () {\n      callback(exports.unstable_now());\n    }, ms);\n  };\n\n  cancelHostTimeout = function () {\n    _clearTimeout(taskTimeoutID);\n\n    taskTimeoutID = -1;\n  };\n}\n\nfunction push(heap, node) {\n  var index = heap.length;\n  heap.push(node);\n  siftUp(heap, node, index);\n}\nfunction peek(heap) {\n  var first = heap[0];\n  return first === undefined ? null : first;\n}\nfunction pop(heap) {\n  var first = heap[0];\n\n  if (first !== undefined) {\n    var last = heap.pop();\n\n    if (last !== first) {\n      heap[0] = last;\n      siftDown(heap, last, 0);\n    }\n\n    return first;\n  } else {\n    return null;\n  }\n}\n\nfunction siftUp(heap, node, i) {\n  var index = i;\n\n  while (true) {\n    var parentIndex = Math.floor((index - 1) / 2);\n    var parent = heap[parentIndex];\n\n    if (parent !== undefined && compare(parent, node) > 0) {\n      // The parent is larger. Swap positions.\n      heap[parentIndex] = node;\n      heap[index] = parent;\n      index = parentIndex;\n    } else {\n      // The parent is smaller. Exit.\n      return;\n    }\n  }\n}\n\nfunction siftDown(heap, node, i) {\n  var index = i;\n  var length = heap.length;\n\n  while (index < length) {\n    var leftIndex = (index + 1) * 2 - 1;\n    var left = heap[leftIndex];\n    var rightIndex = leftIndex + 1;\n    var right = heap[rightIndex]; // If the left or right node is smaller, swap with the smaller of those.\n\n    if (left !== undefined && compare(left, node) < 0) {\n      if (right !== undefined && compare(right, left) < 0) {\n        heap[index] = right;\n        heap[rightIndex] = node;\n        index = rightIndex;\n      } else {\n        heap[index] = left;\n        heap[leftIndex] = node;\n        index = leftIndex;\n      }\n    } else if (right !== undefined && compare(right, node) < 0) {\n      heap[index] = right;\n      heap[rightIndex] = node;\n      index = rightIndex;\n    } else {\n      // Neither child is smaller. Exit.\n      return;\n    }\n  }\n}\n\nfunction compare(a, b) {\n  // Compare sort index first, then task id.\n  var diff = a.sortIndex - b.sortIndex;\n  return diff !== 0 ? diff : a.id - b.id;\n}\n\n// TODO: Use symbols?\nvar NoPriority = 0;\nvar ImmediatePriority = 1;\nvar UserBlockingPriority = 2;\nvar NormalPriority = 3;\nvar LowPriority = 4;\nvar IdlePriority = 5;\n\nvar runIdCounter = 0;\nvar mainThreadIdCounter = 0;\nvar profilingStateSize = 4;\nvar sharedProfilingBuffer = enableProfiling ? // $FlowFixMe Flow doesn't know about SharedArrayBuffer\ntypeof SharedArrayBuffer === 'function' ? new SharedArrayBuffer(profilingStateSize * Int32Array.BYTES_PER_ELEMENT) : // $FlowFixMe Flow doesn't know about ArrayBuffer\ntypeof ArrayBuffer === 'function' ? new ArrayBuffer(profilingStateSize * Int32Array.BYTES_PER_ELEMENT) : null // Don't crash the init path on IE9\n: null;\nvar profilingState = enableProfiling && sharedProfilingBuffer !== null ? new Int32Array(sharedProfilingBuffer) : []; // We can't read this but it helps save bytes for null checks\n\nvar PRIORITY = 0;\nvar CURRENT_TASK_ID = 1;\nvar CURRENT_RUN_ID = 2;\nvar QUEUE_SIZE = 3;\n\nif (enableProfiling) {\n  profilingState[PRIORITY] = NoPriority; // This is maintained with a counter, because the size of the priority queue\n  // array might include canceled tasks.\n\n  profilingState[QUEUE_SIZE] = 0;\n  profilingState[CURRENT_TASK_ID] = 0;\n} // Bytes per element is 4\n\n\nvar INITIAL_EVENT_LOG_SIZE = 131072;\nvar MAX_EVENT_LOG_SIZE = 524288; // Equivalent to 2 megabytes\n\nvar eventLogSize = 0;\nvar eventLogBuffer = null;\nvar eventLog = null;\nvar eventLogIndex = 0;\nvar TaskStartEvent = 1;\nvar TaskCompleteEvent = 2;\nvar TaskErrorEvent = 3;\nvar TaskCancelEvent = 4;\nvar TaskRunEvent = 5;\nvar TaskYieldEvent = 6;\nvar SchedulerSuspendEvent = 7;\nvar SchedulerResumeEvent = 8;\n\nfunction logEvent(entries) {\n  if (eventLog !== null) {\n    var offset = eventLogIndex;\n    eventLogIndex += entries.length;\n\n    if (eventLogIndex + 1 > eventLogSize) {\n      eventLogSize *= 2;\n\n      if (eventLogSize > MAX_EVENT_LOG_SIZE) {\n        console.error(\"Scheduler Profiling: Event log exceeded maximum size. Don't \" + 'forget to call `stopLoggingProfilingEvents()`.');\n        stopLoggingProfilingEvents();\n        return;\n      }\n\n      var newEventLog = new Int32Array(eventLogSize * 4);\n      newEventLog.set(eventLog);\n      eventLogBuffer = newEventLog.buffer;\n      eventLog = newEventLog;\n    }\n\n    eventLog.set(entries, offset);\n  }\n}\n\nfunction startLoggingProfilingEvents() {\n  eventLogSize = INITIAL_EVENT_LOG_SIZE;\n  eventLogBuffer = new ArrayBuffer(eventLogSize * 4);\n  eventLog = new Int32Array(eventLogBuffer);\n  eventLogIndex = 0;\n}\nfunction stopLoggingProfilingEvents() {\n  var buffer = eventLogBuffer;\n  eventLogSize = 0;\n  eventLogBuffer = null;\n  eventLog = null;\n  eventLogIndex = 0;\n  return buffer;\n}\nfunction markTaskStart(task, ms) {\n  if (enableProfiling) {\n    profilingState[QUEUE_SIZE]++;\n\n    if (eventLog !== null) {\n      // performance.now returns a float, representing milliseconds. When the\n      // event is logged, it's coerced to an int. Convert to microseconds to\n      // maintain extra degrees of precision.\n      logEvent([TaskStartEvent, ms * 1000, task.id, task.priorityLevel]);\n    }\n  }\n}\nfunction markTaskCompleted(task, ms) {\n  if (enableProfiling) {\n    profilingState[PRIORITY] = NoPriority;\n    profilingState[CURRENT_TASK_ID] = 0;\n    profilingState[QUEUE_SIZE]--;\n\n    if (eventLog !== null) {\n      logEvent([TaskCompleteEvent, ms * 1000, task.id]);\n    }\n  }\n}\nfunction markTaskCanceled(task, ms) {\n  if (enableProfiling) {\n    profilingState[QUEUE_SIZE]--;\n\n    if (eventLog !== null) {\n      logEvent([TaskCancelEvent, ms * 1000, task.id]);\n    }\n  }\n}\nfunction markTaskErrored(task, ms) {\n  if (enableProfiling) {\n    profilingState[PRIORITY] = NoPriority;\n    profilingState[CURRENT_TASK_ID] = 0;\n    profilingState[QUEUE_SIZE]--;\n\n    if (eventLog !== null) {\n      logEvent([TaskErrorEvent, ms * 1000, task.id]);\n    }\n  }\n}\nfunction markTaskRun(task, ms) {\n  if (enableProfiling) {\n    runIdCounter++;\n    profilingState[PRIORITY] = task.priorityLevel;\n    profilingState[CURRENT_TASK_ID] = task.id;\n    profilingState[CURRENT_RUN_ID] = runIdCounter;\n\n    if (eventLog !== null) {\n      logEvent([TaskRunEvent, ms * 1000, task.id, runIdCounter]);\n    }\n  }\n}\nfunction markTaskYield(task, ms) {\n  if (enableProfiling) {\n    profilingState[PRIORITY] = NoPriority;\n    profilingState[CURRENT_TASK_ID] = 0;\n    profilingState[CURRENT_RUN_ID] = 0;\n\n    if (eventLog !== null) {\n      logEvent([TaskYieldEvent, ms * 1000, task.id, runIdCounter]);\n    }\n  }\n}\nfunction markSchedulerSuspended(ms) {\n  if (enableProfiling) {\n    mainThreadIdCounter++;\n\n    if (eventLog !== null) {\n      logEvent([SchedulerSuspendEvent, ms * 1000, mainThreadIdCounter]);\n    }\n  }\n}\nfunction markSchedulerUnsuspended(ms) {\n  if (enableProfiling) {\n    if (eventLog !== null) {\n      logEvent([SchedulerResumeEvent, ms * 1000, mainThreadIdCounter]);\n    }\n  }\n}\n\n/* eslint-disable no-var */\n// Math.pow(2, 30) - 1\n// 0b111111111111111111111111111111\n\nvar maxSigned31BitInt = 1073741823; // Times out immediately\n\nvar IMMEDIATE_PRIORITY_TIMEOUT = -1; // Eventually times out\n\nvar USER_BLOCKING_PRIORITY = 250;\nvar NORMAL_PRIORITY_TIMEOUT = 5000;\nvar LOW_PRIORITY_TIMEOUT = 10000; // Never times out\n\nvar IDLE_PRIORITY = maxSigned31BitInt; // Tasks are stored on a min heap\n\nvar taskQueue = [];\nvar timerQueue = []; // Incrementing id counter. Used to maintain insertion order.\n\nvar taskIdCounter = 1; // Pausing the scheduler is useful for debugging.\n\nvar isSchedulerPaused = false;\nvar currentTask = null;\nvar currentPriorityLevel = NormalPriority; // This is set while performing work, to prevent re-entrancy.\n\nvar isPerformingWork = false;\nvar isHostCallbackScheduled = false;\nvar isHostTimeoutScheduled = false;\n\nfunction advanceTimers(currentTime) {\n  // Check for tasks that are no longer delayed and add them to the queue.\n  var timer = peek(timerQueue);\n\n  while (timer !== null) {\n    if (timer.callback === null) {\n      // Timer was cancelled.\n      pop(timerQueue);\n    } else if (timer.startTime <= currentTime) {\n      // Timer fired. Transfer to the task queue.\n      pop(timerQueue);\n      timer.sortIndex = timer.expirationTime;\n      push(taskQueue, timer);\n\n      if (enableProfiling) {\n        markTaskStart(timer, currentTime);\n        timer.isQueued = true;\n      }\n    } else {\n      // Remaining timers are pending.\n      return;\n    }\n\n    timer = peek(timerQueue);\n  }\n}\n\nfunction handleTimeout(currentTime) {\n  isHostTimeoutScheduled = false;\n  advanceTimers(currentTime);\n\n  if (!isHostCallbackScheduled) {\n    if (peek(taskQueue) !== null) {\n      isHostCallbackScheduled = true;\n      requestHostCallback(flushWork);\n    } else {\n      var firstTimer = peek(timerQueue);\n\n      if (firstTimer !== null) {\n        requestHostTimeout(handleTimeout, firstTimer.startTime - currentTime);\n      }\n    }\n  }\n}\n\nfunction flushWork(hasTimeRemaining, initialTime) {\n  if (enableProfiling) {\n    markSchedulerUnsuspended(initialTime);\n  } // We'll need a host callback the next time work is scheduled.\n\n\n  isHostCallbackScheduled = false;\n\n  if (isHostTimeoutScheduled) {\n    // We scheduled a timeout but it's no longer needed. Cancel it.\n    isHostTimeoutScheduled = false;\n    cancelHostTimeout();\n  }\n\n  isPerformingWork = true;\n  var previousPriorityLevel = currentPriorityLevel;\n\n  try {\n    if (enableProfiling) {\n      try {\n        return workLoop(hasTimeRemaining, initialTime);\n      } catch (error) {\n        if (currentTask !== null) {\n          var currentTime = exports.unstable_now();\n          markTaskErrored(currentTask, currentTime);\n          currentTask.isQueued = false;\n        }\n\n        throw error;\n      }\n    } else {\n      // No catch in prod codepath.\n      return workLoop(hasTimeRemaining, initialTime);\n    }\n  } finally {\n    currentTask = null;\n    currentPriorityLevel = previousPriorityLevel;\n    isPerformingWork = false;\n\n    if (enableProfiling) {\n      var _currentTime = exports.unstable_now();\n\n      markSchedulerSuspended(_currentTime);\n    }\n  }\n}\n\nfunction workLoop(hasTimeRemaining, initialTime) {\n  var currentTime = initialTime;\n  advanceTimers(currentTime);\n  currentTask = peek(taskQueue);\n\n  while (currentTask !== null && !(enableSchedulerDebugging && isSchedulerPaused)) {\n    if (currentTask.expirationTime > currentTime && (!hasTimeRemaining || shouldYieldToHost())) {\n      // This currentTask hasn't expired, and we've reached the deadline.\n      break;\n    }\n\n    var callback = currentTask.callback;\n\n    if (callback !== null) {\n      currentTask.callback = null;\n      currentPriorityLevel = currentTask.priorityLevel;\n      var didUserCallbackTimeout = currentTask.expirationTime <= currentTime;\n      markTaskRun(currentTask, currentTime);\n      var continuationCallback = callback(didUserCallbackTimeout);\n      currentTime = exports.unstable_now();\n\n      if (typeof continuationCallback === 'function') {\n        currentTask.callback = continuationCallback;\n        markTaskYield(currentTask, currentTime);\n      } else {\n        if (enableProfiling) {\n          markTaskCompleted(currentTask, currentTime);\n          currentTask.isQueued = false;\n        }\n\n        if (currentTask === peek(taskQueue)) {\n          pop(taskQueue);\n        }\n      }\n\n      advanceTimers(currentTime);\n    } else {\n      pop(taskQueue);\n    }\n\n    currentTask = peek(taskQueue);\n  } // Return whether there's additional work\n\n\n  if (currentTask !== null) {\n    return true;\n  } else {\n    var firstTimer = peek(timerQueue);\n\n    if (firstTimer !== null) {\n      requestHostTimeout(handleTimeout, firstTimer.startTime - currentTime);\n    }\n\n    return false;\n  }\n}\n\nfunction unstable_runWithPriority(priorityLevel, eventHandler) {\n  switch (priorityLevel) {\n    case ImmediatePriority:\n    case UserBlockingPriority:\n    case NormalPriority:\n    case LowPriority:\n    case IdlePriority:\n      break;\n\n    default:\n      priorityLevel = NormalPriority;\n  }\n\n  var previousPriorityLevel = currentPriorityLevel;\n  currentPriorityLevel = priorityLevel;\n\n  try {\n    return eventHandler();\n  } finally {\n    currentPriorityLevel = previousPriorityLevel;\n  }\n}\n\nfunction unstable_next(eventHandler) {\n  var priorityLevel;\n\n  switch (currentPriorityLevel) {\n    case ImmediatePriority:\n    case UserBlockingPriority:\n    case NormalPriority:\n      // Shift down to normal priority\n      priorityLevel = NormalPriority;\n      break;\n\n    default:\n      // Anything lower than normal priority should remain at the current level.\n      priorityLevel = currentPriorityLevel;\n      break;\n  }\n\n  var previousPriorityLevel = currentPriorityLevel;\n  currentPriorityLevel = priorityLevel;\n\n  try {\n    return eventHandler();\n  } finally {\n    currentPriorityLevel = previousPriorityLevel;\n  }\n}\n\nfunction unstable_wrapCallback(callback) {\n  var parentPriorityLevel = currentPriorityLevel;\n  return function () {\n    // This is a fork of runWithPriority, inlined for performance.\n    var previousPriorityLevel = currentPriorityLevel;\n    currentPriorityLevel = parentPriorityLevel;\n\n    try {\n      return callback.apply(this, arguments);\n    } finally {\n      currentPriorityLevel = previousPriorityLevel;\n    }\n  };\n}\n\nfunction timeoutForPriorityLevel(priorityLevel) {\n  switch (priorityLevel) {\n    case ImmediatePriority:\n      return IMMEDIATE_PRIORITY_TIMEOUT;\n\n    case UserBlockingPriority:\n      return USER_BLOCKING_PRIORITY;\n\n    case IdlePriority:\n      return IDLE_PRIORITY;\n\n    case LowPriority:\n      return LOW_PRIORITY_TIMEOUT;\n\n    case NormalPriority:\n    default:\n      return NORMAL_PRIORITY_TIMEOUT;\n  }\n}\n\nfunction unstable_scheduleCallback(priorityLevel, callback, options) {\n  var currentTime = exports.unstable_now();\n  var startTime;\n  var timeout;\n\n  if (typeof options === 'object' && options !== null) {\n    var delay = options.delay;\n\n    if (typeof delay === 'number' && delay > 0) {\n      startTime = currentTime + delay;\n    } else {\n      startTime = currentTime;\n    }\n\n    timeout = typeof options.timeout === 'number' ? options.timeout : timeoutForPriorityLevel(priorityLevel);\n  } else {\n    timeout = timeoutForPriorityLevel(priorityLevel);\n    startTime = currentTime;\n  }\n\n  var expirationTime = startTime + timeout;\n  var newTask = {\n    id: taskIdCounter++,\n    callback: callback,\n    priorityLevel: priorityLevel,\n    startTime: startTime,\n    expirationTime: expirationTime,\n    sortIndex: -1\n  };\n\n  if (enableProfiling) {\n    newTask.isQueued = false;\n  }\n\n  if (startTime > currentTime) {\n    // This is a delayed task.\n    newTask.sortIndex = startTime;\n    push(timerQueue, newTask);\n\n    if (peek(taskQueue) === null && newTask === peek(timerQueue)) {\n      // All tasks are delayed, and this is the task with the earliest delay.\n      if (isHostTimeoutScheduled) {\n        // Cancel an existing timeout.\n        cancelHostTimeout();\n      } else {\n        isHostTimeoutScheduled = true;\n      } // Schedule a timeout.\n\n\n      requestHostTimeout(handleTimeout, startTime - currentTime);\n    }\n  } else {\n    newTask.sortIndex = expirationTime;\n    push(taskQueue, newTask);\n\n    if (enableProfiling) {\n      markTaskStart(newTask, currentTime);\n      newTask.isQueued = true;\n    } // Schedule a host callback, if needed. If we're already performing work,\n    // wait until the next time we yield.\n\n\n    if (!isHostCallbackScheduled && !isPerformingWork) {\n      isHostCallbackScheduled = true;\n      requestHostCallback(flushWork);\n    }\n  }\n\n  return newTask;\n}\n\nfunction unstable_pauseExecution() {\n  isSchedulerPaused = true;\n}\n\nfunction unstable_continueExecution() {\n  isSchedulerPaused = false;\n\n  if (!isHostCallbackScheduled && !isPerformingWork) {\n    isHostCallbackScheduled = true;\n    requestHostCallback(flushWork);\n  }\n}\n\nfunction unstable_getFirstCallbackNode() {\n  return peek(taskQueue);\n}\n\nfunction unstable_cancelCallback(task) {\n  if (enableProfiling) {\n    if (task.isQueued) {\n      var currentTime = exports.unstable_now();\n      markTaskCanceled(task, currentTime);\n      task.isQueued = false;\n    }\n  } // Null out the callback to indicate the task has been canceled. (Can't\n  // remove from the queue because you can't remove arbitrary nodes from an\n  // array based heap, only the first one.)\n\n\n  task.callback = null;\n}\n\nfunction unstable_getCurrentPriorityLevel() {\n  return currentPriorityLevel;\n}\n\nfunction unstable_shouldYield() {\n  var currentTime = exports.unstable_now();\n  advanceTimers(currentTime);\n  var firstTask = peek(taskQueue);\n  return firstTask !== currentTask && currentTask !== null && firstTask !== null && firstTask.callback !== null && firstTask.startTime <= currentTime && firstTask.expirationTime < currentTask.expirationTime || shouldYieldToHost();\n}\n\nvar unstable_requestPaint = requestPaint;\nvar unstable_Profiling = enableProfiling ? {\n  startLoggingProfilingEvents: startLoggingProfilingEvents,\n  stopLoggingProfilingEvents: stopLoggingProfilingEvents,\n  sharedProfilingBuffer: sharedProfilingBuffer\n} : null;\n\nexports.unstable_ImmediatePriority = ImmediatePriority;\nexports.unstable_UserBlockingPriority = UserBlockingPriority;\nexports.unstable_NormalPriority = NormalPriority;\nexports.unstable_IdlePriority = IdlePriority;\nexports.unstable_LowPriority = LowPriority;\nexports.unstable_runWithPriority = unstable_runWithPriority;\nexports.unstable_next = unstable_next;\nexports.unstable_scheduleCallback = unstable_scheduleCallback;\nexports.unstable_cancelCallback = unstable_cancelCallback;\nexports.unstable_wrapCallback = unstable_wrapCallback;\nexports.unstable_getCurrentPriorityLevel = unstable_getCurrentPriorityLevel;\nexports.unstable_shouldYield = unstable_shouldYield;\nexports.unstable_requestPaint = unstable_requestPaint;\nexports.unstable_continueExecution = unstable_continueExecution;\nexports.unstable_pauseExecution = unstable_pauseExecution;\nexports.unstable_getFirstCallbackNode = unstable_getFirstCallbackNode;\nexports.unstable_Profiling = unstable_Profiling;\n  })();\n}\n\n\n//# sourceURL=webpack:///./node_modules/scheduler/cjs/scheduler.development.js?");

/***/ }),

/***/ "./node_modules/scheduler/index.js":
/*!*****************************************!*\
  !*** ./node_modules/scheduler/index.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/scheduler.development.js */ \"./node_modules/scheduler/cjs/scheduler.development.js\");\n}\n\n\n//# sourceURL=webpack:///./node_modules/scheduler/index.js?");

/***/ }),

/***/ "./node_modules/scheduler/tracing.js":
/*!*******************************************!*\
  !*** ./node_modules/scheduler/tracing.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nif (false) {} else {\n  module.exports = __webpack_require__(/*! ./cjs/scheduler-tracing.development.js */ \"./node_modules/scheduler/cjs/scheduler-tracing.development.js\");\n}\n\n\n//# sourceURL=webpack:///./node_modules/scheduler/tracing.js?");

/***/ })

}]);